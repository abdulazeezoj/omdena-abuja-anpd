{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 images found\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "# download dataset\n",
    "!wget https://github.com/abdulazeezoj/omdena-abuja-anpd/raw/main/yolov4.zip\n",
    "\n",
    "# unzip out dataset\n",
    "!unzip anpd.zip\n",
    "\n",
    "# make train.txt and test.txt file\n",
    "file_train = open('/content/anpd/train.txt', 'w')\n",
    "file_test = open('/content/anpd/test.txt', 'w')\n",
    "\n",
    "img_list = glob.glob(f\"/content/anpd/obj/*.jpg\", recursive=False)\n",
    "dataset_size = len(img_list)\n",
    "train_pct = 0.9\n",
    "\n",
    "train_idx = round(dataset_size * train_pct)\n",
    "print(f\"{len(img_list)} images found\")\n",
    "for i, img in enumerate(img_list, 1):\n",
    "    file_train.write(img.replace(\"\\\\\", \"/\") + \"\\n\")\n",
    "    \n",
    "    if i > train_idx:\n",
    "        file_test.write(img.replace(\"\\\\\", \"/\") + \"\\n\")\n",
    "\n",
    "file_train.close()\n",
    "file_test.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ANPD with YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone darknet repository\n",
    "!git clone https://github.com/AlexeyAB/darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build darknet\n",
    "%cd darknet\n",
    "\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
    "!sed -i 's/OPENMP=0/OPENMP=1/' Makefile\n",
    "\n",
    "!make\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP**: This training could take several hours depending on how many iterations you chose in the .cfg file. You will want to let this run as you sleep or go to work for the day, etc. However, Colab Cloud Service kicks you off it's VMs if you are idle for too long (30-90 mins).\n",
    "\n",
    "To avoid this hold (CTRL + SHIFT + i) at the same time to open up the inspector view on your browser.\n",
    "\n",
    "Paste the following code into your console window and hit Enter\n",
    "```\n",
    "function ClickConnect(){\n",
    "console.log(\"Working\"); \n",
    "document\n",
    "  .querySelector('#top-toolbar > colab-connect-button')\n",
    "  .shadowRoot.querySelector('#connect')\n",
    "  .click() \n",
    "}\n",
    "setInterval(ClickConnect,60000)\n",
    "```\n",
    "Looks like this, it will click the screen every 10 minutes so that you don't get kicked off for being idle! HACKS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to start training from last pre-trained weights*\n",
    "\n",
    "<!-- remove the comment sign above and below\n",
    "# starting training from last pre-trained weights [optional]\n",
    "\n",
    "!./darknet detector train /content/anpd/anpd.data /content/anpd/anpd.cfg /content/anpd/out/anpd_best.weights -dont_show -map\n",
    "change cell to code to run it-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "\n",
    "!./darknet detector train /content/anpd/anpd.data /content/anpd/anpd.cfg /content/anpd/yolov4-tiny.conv.29 -dont_show -map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to resume training from last weights*\n",
    "\n",
    "<!-- remove the comment sign above and below\n",
    "# resuming training from last weights [optional]\n",
    "\n",
    "!./darknet detector train /content/anpd/anpd.data /content/anpd/anpd.cfg /content/anpd/out/obj_last.weights - dont_show - map\n",
    "chane cell to code to run it-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mAP\n",
    "\n",
    "!./darknet detector map /content/anpd/anpd.data /content/anpd/anpd.cfg /content/anpd/out/obj_best.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading YOLO from disk...\n",
      "[INFO] detecting object(s)...\n",
      "[INFO] YOLO took 0.264002 seconds\n"
     ]
    }
   ],
   "source": [
    "# testing the ANPD model on image\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "# load our input image and grab its spatial dimensions\n",
    "image = cv2.imread(\"/content/anpd/inf/img1.jpg\")\n",
    "\n",
    "# load the objects class names our YOLO model was trained on\n",
    "with open(\"/content/anpd/anpd.names\", 'r') as f:\n",
    "    classNames = f.read().splitlines()\n",
    "\n",
    "# load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(\"/content/anpd/anpd.cfg\",\n",
    "                                 \"/content/anpd/out/obj_best.weights\")\n",
    "model = cv2.dnn_DetectionModel(net)\n",
    "model.setInputParams(scale=1/255, size=(416, 416), swapRB=True)\n",
    "\n",
    "\n",
    "# start detecting object and show timing information on YOLO\n",
    "start = time.time()\n",
    "\n",
    "print(\"[INFO] detecting object(s)...\")\n",
    "classIds, scores, boxes = model.detect(\n",
    "    image, confThreshold=0.5, nmsThreshold=0.5)\n",
    "\n",
    "end = time.time()\n",
    "print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "\n",
    "# initialize detected bounding boxes, confidences, and class IDs, respectively\n",
    "for (classId, score, box) in zip(classIds, scores, boxes):\n",
    "    cv2.rectangle(image, (box[0], box[1]), (box[0] + box[2], box[1] + box[3]),\n",
    "                  color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    text = '%s: %.2f' % (classNames[classId], score)\n",
    "    cv2.putText(image, text, (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                color=(0, 255, 0), thickness=1)\n",
    "\n",
    "\n",
    "# display result\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export your model's weights for future use\n",
    "from google.colab import files\n",
    "files.download('/content/anpd/out/obj_best.weights')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
